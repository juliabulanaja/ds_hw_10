{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ff7840-8dfd-4c78-8da8-ddb4f25db43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd62f3e1-608e-4355-b651-efa639d0cc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "x_train = train_images[10000:]\n",
    "x_validation = train_images[:10000]\n",
    "\n",
    "y_train = train_labels[10000:]\n",
    "y_validation = train_labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe9425f6-413d-4967-a280-057364ace919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(activation='relu', regularizer=0.0):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=activation, input_shape=(28, 28, 1), kernel_regularizer=regularizers.L2(regularizer)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation=activation, kernel_regularizer=regularizers.L2(regularizer)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation=activation, kernel_regularizer=regularizers.L2(regularizer)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.Dense(32, activation=activation, kernel_regularizer=regularizers.L2(regularizer)),\n",
    "        # layers.Dropout(0.1),\n",
    "\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab6dec6-597e-4249-9fee-e638c94f253c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.6111 - accuracy: 0.5509\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74740, saving model to best_model.keras\n",
      "49/49 [==============================] - 6s 61ms/step - loss: 1.6111 - accuracy: 0.5509 - val_loss: 0.9677 - val_accuracy: 0.7474\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.9310 - accuracy: 0.7512\n",
      "Epoch 2: val_accuracy improved from 0.74740 to 0.78810, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9310 - accuracy: 0.7512 - val_loss: 0.8093 - val_accuracy: 0.7881\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.8147 - accuracy: 0.7822\n",
      "Epoch 3: val_accuracy improved from 0.78810 to 0.81180, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.8147 - accuracy: 0.7822 - val_loss: 0.7331 - val_accuracy: 0.8118\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.7433 - accuracy: 0.8028\n",
      "Epoch 4: val_accuracy improved from 0.81180 to 0.82280, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7433 - accuracy: 0.8028 - val_loss: 0.6841 - val_accuracy: 0.8228\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.8126\n",
      "Epoch 5: val_accuracy improved from 0.82280 to 0.83040, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.6970 - accuracy: 0.8126 - val_loss: 0.6441 - val_accuracy: 0.8304\n",
      "Epoch 6/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.6602 - accuracy: 0.8243\n",
      "Epoch 6: val_accuracy improved from 0.83040 to 0.84080, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.6600 - accuracy: 0.8242 - val_loss: 0.6156 - val_accuracy: 0.8408\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.8317\n",
      "Epoch 7: val_accuracy improved from 0.84080 to 0.85130, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.6320 - accuracy: 0.8317 - val_loss: 0.5904 - val_accuracy: 0.8513\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.8378\n",
      "Epoch 8: val_accuracy did not improve from 0.85130\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.6091 - accuracy: 0.8378 - val_loss: 0.5732 - val_accuracy: 0.8508\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.8417\n",
      "Epoch 9: val_accuracy improved from 0.85130 to 0.85210, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.5903 - accuracy: 0.8417 - val_loss: 0.5600 - val_accuracy: 0.8521\n",
      "Epoch 10/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.5744 - accuracy: 0.8445\n",
      "Epoch 10: val_accuracy improved from 0.85210 to 0.86490, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.5734 - accuracy: 0.8448 - val_loss: 0.5359 - val_accuracy: 0.8649\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.8507\n",
      "Epoch 11: val_accuracy did not improve from 0.86490\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.5575 - accuracy: 0.8507 - val_loss: 0.5254 - val_accuracy: 0.8632\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.8521\n",
      "Epoch 12: val_accuracy did not improve from 0.86490\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.5486 - accuracy: 0.8521 - val_loss: 0.5183 - val_accuracy: 0.8638\n",
      "Epoch 13/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.5381 - accuracy: 0.8549\n",
      "Epoch 13: val_accuracy improved from 0.86490 to 0.86660, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5386 - accuracy: 0.8549 - val_loss: 0.5112 - val_accuracy: 0.8666\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8582\n",
      "Epoch 14: val_accuracy improved from 0.86660 to 0.86810, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.5299 - accuracy: 0.8582 - val_loss: 0.4973 - val_accuracy: 0.8681\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.8598\n",
      "Epoch 15: val_accuracy improved from 0.86810 to 0.87310, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.5196 - accuracy: 0.8598 - val_loss: 0.4897 - val_accuracy: 0.8731\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8631\n",
      "Epoch 16: val_accuracy improved from 0.87310 to 0.87560, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.5126 - accuracy: 0.8631 - val_loss: 0.4805 - val_accuracy: 0.8756\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.8620\n",
      "Epoch 17: val_accuracy did not improve from 0.87560\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.5088 - accuracy: 0.8620 - val_loss: 0.4831 - val_accuracy: 0.8735\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.8639\n",
      "Epoch 18: val_accuracy did not improve from 0.87560\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.5046 - accuracy: 0.8639 - val_loss: 0.4965 - val_accuracy: 0.8657\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.8642\n",
      "Epoch 19: val_accuracy improved from 0.87560 to 0.87820, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.5020 - accuracy: 0.8642 - val_loss: 0.4673 - val_accuracy: 0.8782\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.8666\n",
      "Epoch 20: val_accuracy did not improve from 0.87820\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4947 - accuracy: 0.8666 - val_loss: 0.4699 - val_accuracy: 0.8770\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.8647\n",
      "Epoch 21: val_accuracy improved from 0.87820 to 0.88000, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4950 - accuracy: 0.8647 - val_loss: 0.4687 - val_accuracy: 0.8800\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.8695\n",
      "Epoch 22: val_accuracy improved from 0.88000 to 0.88130, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4882 - accuracy: 0.8695 - val_loss: 0.4602 - val_accuracy: 0.8813\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.8689\n",
      "Epoch 23: val_accuracy did not improve from 0.88130\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.4827 - accuracy: 0.8689 - val_loss: 0.4543 - val_accuracy: 0.8813\n",
      "Epoch 24/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.8710\n",
      "Epoch 24: val_accuracy did not improve from 0.88130\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4796 - accuracy: 0.8710 - val_loss: 0.4662 - val_accuracy: 0.8744\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.8698\n",
      "Epoch 25: val_accuracy did not improve from 0.88130\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4784 - accuracy: 0.8698 - val_loss: 0.4594 - val_accuracy: 0.8781\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.8725\n",
      "Epoch 26: val_accuracy improved from 0.88130 to 0.88260, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4761 - accuracy: 0.8725 - val_loss: 0.4489 - val_accuracy: 0.8826\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.8731\n",
      "Epoch 27: val_accuracy did not improve from 0.88260\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4707 - accuracy: 0.8731 - val_loss: 0.4479 - val_accuracy: 0.8814\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4697 - accuracy: 0.8738\n",
      "Epoch 28: val_accuracy did not improve from 0.88260\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4697 - accuracy: 0.8738 - val_loss: 0.4538 - val_accuracy: 0.8794\n",
      "Epoch 29/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.8734\n",
      "Epoch 29: val_accuracy improved from 0.88260 to 0.88270, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4710 - accuracy: 0.8732 - val_loss: 0.4438 - val_accuracy: 0.8827\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8742\n",
      "Epoch 30: val_accuracy did not improve from 0.88270\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4674 - accuracy: 0.8742 - val_loss: 0.4537 - val_accuracy: 0.8807\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.8740\n",
      "Epoch 31: val_accuracy improved from 0.88270 to 0.88370, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.4661 - accuracy: 0.8740 - val_loss: 0.4459 - val_accuracy: 0.8837\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8755\n",
      "Epoch 32: val_accuracy did not improve from 0.88370\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4642 - accuracy: 0.8755 - val_loss: 0.4436 - val_accuracy: 0.8813\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8768\n",
      "Epoch 33: val_accuracy improved from 0.88370 to 0.88550, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4609 - accuracy: 0.8768 - val_loss: 0.4357 - val_accuracy: 0.8855\n",
      "Epoch 34/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4596 - accuracy: 0.8768\n",
      "Epoch 34: val_accuracy improved from 0.88550 to 0.88670, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4601 - accuracy: 0.8766 - val_loss: 0.4349 - val_accuracy: 0.8867\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.8781\n",
      "Epoch 35: val_accuracy improved from 0.88670 to 0.88720, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4566 - accuracy: 0.8781 - val_loss: 0.4348 - val_accuracy: 0.8872\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.8776\n",
      "Epoch 36: val_accuracy did not improve from 0.88720\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4554 - accuracy: 0.8776 - val_loss: 0.4374 - val_accuracy: 0.8852\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.8782\n",
      "Epoch 37: val_accuracy did not improve from 0.88720\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4562 - accuracy: 0.8782 - val_loss: 0.4354 - val_accuracy: 0.8861\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8780\n",
      "Epoch 38: val_accuracy did not improve from 0.88720\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4531 - accuracy: 0.8780 - val_loss: 0.4345 - val_accuracy: 0.8865\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8793\n",
      "Epoch 39: val_accuracy did not improve from 0.88720\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4510 - accuracy: 0.8793 - val_loss: 0.4311 - val_accuracy: 0.8835\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.8814\n",
      "Epoch 40: val_accuracy did not improve from 0.88720\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4465 - accuracy: 0.8814 - val_loss: 0.4328 - val_accuracy: 0.8852\n",
      "Epoch 41/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4512 - accuracy: 0.8799\n",
      "Epoch 41: val_accuracy did not improve from 0.88720\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4507 - accuracy: 0.8801 - val_loss: 0.4344 - val_accuracy: 0.8834\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8817\n",
      "Epoch 42: val_accuracy did not improve from 0.88720\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4459 - accuracy: 0.8817 - val_loss: 0.4254 - val_accuracy: 0.8868\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8831\n",
      "Epoch 43: val_accuracy improved from 0.88720 to 0.89060, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4426 - accuracy: 0.8831 - val_loss: 0.4226 - val_accuracy: 0.8906\n",
      "Epoch 44/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4438 - accuracy: 0.8831\n",
      "Epoch 44: val_accuracy improved from 0.89060 to 0.89100, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4436 - accuracy: 0.8832 - val_loss: 0.4262 - val_accuracy: 0.8910\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.8810\n",
      "Epoch 45: val_accuracy improved from 0.89100 to 0.89110, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4455 - accuracy: 0.8810 - val_loss: 0.4188 - val_accuracy: 0.8911\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.8821\n",
      "Epoch 46: val_accuracy did not improve from 0.89110\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4423 - accuracy: 0.8821 - val_loss: 0.4228 - val_accuracy: 0.8887\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.8836\n",
      "Epoch 47: val_accuracy did not improve from 0.89110\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.4408 - accuracy: 0.8836 - val_loss: 0.4274 - val_accuracy: 0.8878\n",
      "Epoch 48/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4364 - accuracy: 0.8851\n",
      "Epoch 48: val_accuracy did not improve from 0.89110\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4366 - accuracy: 0.8848 - val_loss: 0.4172 - val_accuracy: 0.8905\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4379 - accuracy: 0.8841\n",
      "Epoch 49: val_accuracy did not improve from 0.89110\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4379 - accuracy: 0.8841 - val_loss: 0.4293 - val_accuracy: 0.8900\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.8846\n",
      "Epoch 50: val_accuracy improved from 0.89110 to 0.89410, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4334 - accuracy: 0.8846 - val_loss: 0.4139 - val_accuracy: 0.8941\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8827\n",
      "Epoch 51: val_accuracy did not improve from 0.89410\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4377 - accuracy: 0.8827 - val_loss: 0.4173 - val_accuracy: 0.8908\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.8841\n",
      "Epoch 52: val_accuracy did not improve from 0.89410\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4351 - accuracy: 0.8841 - val_loss: 0.4139 - val_accuracy: 0.8934\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4325 - accuracy: 0.8853\n",
      "Epoch 53: val_accuracy improved from 0.89410 to 0.89470, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4325 - accuracy: 0.8853 - val_loss: 0.4104 - val_accuracy: 0.8947\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8827\n",
      "Epoch 54: val_accuracy did not improve from 0.89470\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4370 - accuracy: 0.8827 - val_loss: 0.4191 - val_accuracy: 0.8928\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.8872\n",
      "Epoch 55: val_accuracy did not improve from 0.89470\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4302 - accuracy: 0.8872 - val_loss: 0.4133 - val_accuracy: 0.8947\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.8872\n",
      "Epoch 56: val_accuracy did not improve from 0.89470\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4300 - accuracy: 0.8872 - val_loss: 0.4104 - val_accuracy: 0.8941\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.8863\n",
      "Epoch 57: val_accuracy did not improve from 0.89470\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4311 - accuracy: 0.8863 - val_loss: 0.4120 - val_accuracy: 0.8939\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.8867\n",
      "Epoch 58: val_accuracy did not improve from 0.89470\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4277 - accuracy: 0.8867 - val_loss: 0.4239 - val_accuracy: 0.8846\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8888\n",
      "Epoch 59: val_accuracy improved from 0.89470 to 0.89690, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4257 - accuracy: 0.8888 - val_loss: 0.4041 - val_accuracy: 0.8969\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8864\n",
      "Epoch 60: val_accuracy did not improve from 0.89690\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.4267 - accuracy: 0.8864 - val_loss: 0.4118 - val_accuracy: 0.8920\n",
      "Epoch 61/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4249 - accuracy: 0.8882\n",
      "Epoch 61: val_accuracy did not improve from 0.89690\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4254 - accuracy: 0.8880 - val_loss: 0.4042 - val_accuracy: 0.8966\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.8878\n",
      "Epoch 62: val_accuracy did not improve from 0.89690\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4266 - accuracy: 0.8878 - val_loss: 0.4092 - val_accuracy: 0.8944\n",
      "Epoch 63/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4269 - accuracy: 0.8883\n",
      "Epoch 63: val_accuracy did not improve from 0.89690\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4272 - accuracy: 0.8880 - val_loss: 0.4085 - val_accuracy: 0.8948\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8873\n",
      "Epoch 64: val_accuracy did not improve from 0.89690\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4268 - accuracy: 0.8873 - val_loss: 0.4061 - val_accuracy: 0.8944\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.8901\n",
      "Epoch 65: val_accuracy improved from 0.89690 to 0.89710, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4214 - accuracy: 0.8901 - val_loss: 0.4053 - val_accuracy: 0.8971\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.8914\n",
      "Epoch 66: val_accuracy did not improve from 0.89710\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.4174 - accuracy: 0.8914 - val_loss: 0.4068 - val_accuracy: 0.8956\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.8893\n",
      "Epoch 67: val_accuracy improved from 0.89710 to 0.89740, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4209 - accuracy: 0.8893 - val_loss: 0.4020 - val_accuracy: 0.8974\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.8899\n",
      "Epoch 68: val_accuracy did not improve from 0.89740\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4205 - accuracy: 0.8899 - val_loss: 0.4056 - val_accuracy: 0.8956\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8891\n",
      "Epoch 69: val_accuracy improved from 0.89740 to 0.89970, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4229 - accuracy: 0.8891 - val_loss: 0.4004 - val_accuracy: 0.8997\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4181 - accuracy: 0.8918\n",
      "Epoch 70: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4181 - accuracy: 0.8918 - val_loss: 0.4059 - val_accuracy: 0.8955\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8905\n",
      "Epoch 71: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4169 - accuracy: 0.8905 - val_loss: 0.4032 - val_accuracy: 0.8956\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8888\n",
      "Epoch 72: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4208 - accuracy: 0.8888 - val_loss: 0.4007 - val_accuracy: 0.8966\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.8924\n",
      "Epoch 73: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4150 - accuracy: 0.8924 - val_loss: 0.3980 - val_accuracy: 0.8985\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8919\n",
      "Epoch 74: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4156 - accuracy: 0.8919 - val_loss: 0.4029 - val_accuracy: 0.8963\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.8925\n",
      "Epoch 75: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4122 - accuracy: 0.8925 - val_loss: 0.3971 - val_accuracy: 0.8980\n",
      "Epoch 76/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.8916\n",
      "Epoch 76: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4135 - accuracy: 0.8916 - val_loss: 0.3968 - val_accuracy: 0.8985\n",
      "Epoch 77/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4134 - accuracy: 0.8911\n",
      "Epoch 77: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4137 - accuracy: 0.8910 - val_loss: 0.4114 - val_accuracy: 0.8918\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8926\n",
      "Epoch 78: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4115 - accuracy: 0.8926 - val_loss: 0.3990 - val_accuracy: 0.8973\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.8922\n",
      "Epoch 79: val_accuracy did not improve from 0.89970\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4120 - accuracy: 0.8922 - val_loss: 0.4047 - val_accuracy: 0.8930\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.8917\n",
      "Epoch 80: val_accuracy improved from 0.89970 to 0.90050, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4124 - accuracy: 0.8917 - val_loss: 0.3933 - val_accuracy: 0.9005\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.8924\n",
      "Epoch 81: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4101 - accuracy: 0.8924 - val_loss: 0.3971 - val_accuracy: 0.8984\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.8932\n",
      "Epoch 82: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4095 - accuracy: 0.8932 - val_loss: 0.4091 - val_accuracy: 0.8943\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.8913\n",
      "Epoch 83: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4114 - accuracy: 0.8913 - val_loss: 0.3941 - val_accuracy: 0.8971\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.8940\n",
      "Epoch 84: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4098 - accuracy: 0.8940 - val_loss: 0.3950 - val_accuracy: 0.8982\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.8937\n",
      "Epoch 85: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4081 - accuracy: 0.8937 - val_loss: 0.3893 - val_accuracy: 0.8996\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.8925\n",
      "Epoch 86: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4075 - accuracy: 0.8925 - val_loss: 0.3996 - val_accuracy: 0.8979\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.8924\n",
      "Epoch 87: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4108 - accuracy: 0.8924 - val_loss: 0.3930 - val_accuracy: 0.8984\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8940\n",
      "Epoch 88: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4067 - accuracy: 0.8940 - val_loss: 0.4029 - val_accuracy: 0.8935\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.8944\n",
      "Epoch 89: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4052 - accuracy: 0.8944 - val_loss: 0.3913 - val_accuracy: 0.8986\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.8920\n",
      "Epoch 90: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4096 - accuracy: 0.8920 - val_loss: 0.3971 - val_accuracy: 0.8959\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.8934\n",
      "Epoch 91: val_accuracy did not improve from 0.90050\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4060 - accuracy: 0.8934 - val_loss: 0.3963 - val_accuracy: 0.8974\n",
      "Epoch 92/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4086 - accuracy: 0.8933\n",
      "Epoch 92: val_accuracy improved from 0.90050 to 0.90100, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4083 - accuracy: 0.8935 - val_loss: 0.3916 - val_accuracy: 0.9010\n",
      "Epoch 93/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4034 - accuracy: 0.8934\n",
      "Epoch 93: val_accuracy did not improve from 0.90100\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4040 - accuracy: 0.8932 - val_loss: 0.3959 - val_accuracy: 0.8983\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.8952\n",
      "Epoch 94: val_accuracy did not improve from 0.90100\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4034 - accuracy: 0.8952 - val_loss: 0.3928 - val_accuracy: 0.9000\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8960\n",
      "Epoch 95: val_accuracy did not improve from 0.90100\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4011 - accuracy: 0.8960 - val_loss: 0.3916 - val_accuracy: 0.8985\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.8962\n",
      "Epoch 96: val_accuracy improved from 0.90100 to 0.90300, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4018 - accuracy: 0.8962 - val_loss: 0.3848 - val_accuracy: 0.9030\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.8935\n",
      "Epoch 97: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4054 - accuracy: 0.8935 - val_loss: 0.3893 - val_accuracy: 0.9002\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.8955\n",
      "Epoch 98: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.4026 - accuracy: 0.8955 - val_loss: 0.3856 - val_accuracy: 0.9010\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8967\n",
      "Epoch 99: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3991 - accuracy: 0.8967 - val_loss: 0.3885 - val_accuracy: 0.9019\n",
      "Epoch 100/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4007 - accuracy: 0.8954\n",
      "Epoch 100: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.4010 - accuracy: 0.8953 - val_loss: 0.3855 - val_accuracy: 0.9004\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.8948\n",
      "Epoch 101: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4013 - accuracy: 0.8948 - val_loss: 0.3834 - val_accuracy: 0.9012\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8974\n",
      "Epoch 102: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3983 - accuracy: 0.8974 - val_loss: 0.3844 - val_accuracy: 0.9016\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8971\n",
      "Epoch 103: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3982 - accuracy: 0.8971 - val_loss: 0.3993 - val_accuracy: 0.8939\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8958\n",
      "Epoch 104: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3992 - accuracy: 0.8958 - val_loss: 0.3825 - val_accuracy: 0.9026\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8965\n",
      "Epoch 105: val_accuracy did not improve from 0.90300\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.3970 - accuracy: 0.8965 - val_loss: 0.3850 - val_accuracy: 0.8998\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8954\n",
      "Epoch 106: val_accuracy improved from 0.90300 to 0.90330, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.3983 - accuracy: 0.8954 - val_loss: 0.3797 - val_accuracy: 0.9033\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.8959\n",
      "Epoch 107: val_accuracy improved from 0.90330 to 0.90350, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.3968 - accuracy: 0.8959 - val_loss: 0.3832 - val_accuracy: 0.9035\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.8966\n",
      "Epoch 108: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.3940 - accuracy: 0.8966 - val_loss: 0.3890 - val_accuracy: 0.8988\n",
      "Epoch 109/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3966 - accuracy: 0.8966\n",
      "Epoch 109: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3964 - accuracy: 0.8969 - val_loss: 0.3855 - val_accuracy: 0.9006\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.8986\n",
      "Epoch 110: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3938 - accuracy: 0.8986 - val_loss: 0.3812 - val_accuracy: 0.9026\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.8981\n",
      "Epoch 111: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3935 - accuracy: 0.8981 - val_loss: 0.3817 - val_accuracy: 0.9019\n",
      "Epoch 112/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3934 - accuracy: 0.8972\n",
      "Epoch 112: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3934 - accuracy: 0.8972 - val_loss: 0.3810 - val_accuracy: 0.9032\n",
      "Epoch 113/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8996\n",
      "Epoch 113: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3908 - accuracy: 0.8996 - val_loss: 0.3831 - val_accuracy: 0.9011\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8976\n",
      "Epoch 114: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3927 - accuracy: 0.8976 - val_loss: 0.3801 - val_accuracy: 0.9033\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.8973\n",
      "Epoch 115: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3931 - accuracy: 0.8973 - val_loss: 0.3823 - val_accuracy: 0.9021\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.8991\n",
      "Epoch 116: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3915 - accuracy: 0.8991 - val_loss: 0.3896 - val_accuracy: 0.8971\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.8964\n",
      "Epoch 117: val_accuracy did not improve from 0.90350\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3941 - accuracy: 0.8964 - val_loss: 0.3920 - val_accuracy: 0.8988\n",
      "Epoch 118/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.8961\n",
      "Epoch 118: val_accuracy improved from 0.90350 to 0.90480, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3948 - accuracy: 0.8961 - val_loss: 0.3757 - val_accuracy: 0.9048\n",
      "Epoch 119/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8982\n",
      "Epoch 119: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3918 - accuracy: 0.8980 - val_loss: 0.3835 - val_accuracy: 0.8999\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8993\n",
      "Epoch 120: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3882 - accuracy: 0.8993 - val_loss: 0.3816 - val_accuracy: 0.9030\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.8975\n",
      "Epoch 121: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3915 - accuracy: 0.8975 - val_loss: 0.3832 - val_accuracy: 0.9008\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8996\n",
      "Epoch 122: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3875 - accuracy: 0.8996 - val_loss: 0.3861 - val_accuracy: 0.8987\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.8980\n",
      "Epoch 123: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3916 - accuracy: 0.8980 - val_loss: 0.3795 - val_accuracy: 0.9022\n",
      "Epoch 124/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.9002\n",
      "Epoch 124: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.3884 - accuracy: 0.9001 - val_loss: 0.3770 - val_accuracy: 0.9030\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8994\n",
      "Epoch 125: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3873 - accuracy: 0.8994 - val_loss: 0.3764 - val_accuracy: 0.9047\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.8994\n",
      "Epoch 126: val_accuracy did not improve from 0.90480\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3902 - accuracy: 0.8994 - val_loss: 0.3775 - val_accuracy: 0.9047\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8980\n",
      "Epoch 127: val_accuracy improved from 0.90480 to 0.90520, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3891 - accuracy: 0.8980 - val_loss: 0.3772 - val_accuracy: 0.9052\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8999\n",
      "Epoch 128: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3877 - accuracy: 0.8999 - val_loss: 0.3811 - val_accuracy: 0.9021\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.9002\n",
      "Epoch 129: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3889 - accuracy: 0.9002 - val_loss: 0.3754 - val_accuracy: 0.9017\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3907 - accuracy: 0.8970\n",
      "Epoch 130: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3907 - accuracy: 0.8970 - val_loss: 0.3757 - val_accuracy: 0.9047\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.9005\n",
      "Epoch 131: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3862 - accuracy: 0.9005 - val_loss: 0.3725 - val_accuracy: 0.9036\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8999\n",
      "Epoch 132: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3863 - accuracy: 0.8999 - val_loss: 0.3772 - val_accuracy: 0.9028\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.9008\n",
      "Epoch 133: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3822 - accuracy: 0.9008 - val_loss: 0.3853 - val_accuracy: 0.8992\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.8985\n",
      "Epoch 134: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3888 - accuracy: 0.8985 - val_loss: 0.3830 - val_accuracy: 0.9006\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.9004\n",
      "Epoch 135: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3847 - accuracy: 0.9004 - val_loss: 0.3771 - val_accuracy: 0.9028\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8996\n",
      "Epoch 136: val_accuracy did not improve from 0.90520\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3843 - accuracy: 0.8996 - val_loss: 0.3731 - val_accuracy: 0.9038\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.9007\n",
      "Epoch 137: val_accuracy improved from 0.90520 to 0.90610, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3832 - accuracy: 0.9007 - val_loss: 0.3696 - val_accuracy: 0.9061\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.9019\n",
      "Epoch 138: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3817 - accuracy: 0.9019 - val_loss: 0.3708 - val_accuracy: 0.9046\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8993\n",
      "Epoch 139: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3831 - accuracy: 0.8993 - val_loss: 0.3754 - val_accuracy: 0.9043\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8998\n",
      "Epoch 140: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3850 - accuracy: 0.8998 - val_loss: 0.3744 - val_accuracy: 0.9043\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8991\n",
      "Epoch 141: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3872 - accuracy: 0.8991 - val_loss: 0.3753 - val_accuracy: 0.9036\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.9002\n",
      "Epoch 142: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3830 - accuracy: 0.9002 - val_loss: 0.3816 - val_accuracy: 0.8999\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.9008\n",
      "Epoch 143: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3842 - accuracy: 0.9008 - val_loss: 0.3761 - val_accuracy: 0.9015\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8993\n",
      "Epoch 144: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3810 - accuracy: 0.8993 - val_loss: 0.3763 - val_accuracy: 0.9020\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8998\n",
      "Epoch 145: val_accuracy did not improve from 0.90610\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3843 - accuracy: 0.8998 - val_loss: 0.3690 - val_accuracy: 0.9056\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.9031\n",
      "Epoch 146: val_accuracy improved from 0.90610 to 0.90630, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3780 - accuracy: 0.9031 - val_loss: 0.3694 - val_accuracy: 0.9063\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.9028\n",
      "Epoch 147: val_accuracy did not improve from 0.90630\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3777 - accuracy: 0.9028 - val_loss: 0.3708 - val_accuracy: 0.9037\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.9024\n",
      "Epoch 148: val_accuracy did not improve from 0.90630\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3797 - accuracy: 0.9024 - val_loss: 0.3778 - val_accuracy: 0.9020\n",
      "Epoch 149/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.9021\n",
      "Epoch 149: val_accuracy did not improve from 0.90630\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3775 - accuracy: 0.9021 - val_loss: 0.3698 - val_accuracy: 0.9059\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.9035\n",
      "Epoch 150: val_accuracy improved from 0.90630 to 0.90720, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3765 - accuracy: 0.9035 - val_loss: 0.3666 - val_accuracy: 0.9072\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.9004\n",
      "Epoch 151: val_accuracy did not improve from 0.90720\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3786 - accuracy: 0.9004 - val_loss: 0.3730 - val_accuracy: 0.9042\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.9020\n",
      "Epoch 152: val_accuracy did not improve from 0.90720\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3793 - accuracy: 0.9020 - val_loss: 0.3943 - val_accuracy: 0.8950\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.9012\n",
      "Epoch 153: val_accuracy did not improve from 0.90720\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3816 - accuracy: 0.9012 - val_loss: 0.3716 - val_accuracy: 0.9050\n",
      "Epoch 154/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.9023\n",
      "Epoch 154: val_accuracy improved from 0.90720 to 0.90740, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3792 - accuracy: 0.9023 - val_loss: 0.3650 - val_accuracy: 0.9074\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.9033\n",
      "Epoch 155: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3756 - accuracy: 0.9033 - val_loss: 0.3716 - val_accuracy: 0.9036\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.9029\n",
      "Epoch 156: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3755 - accuracy: 0.9029 - val_loss: 0.3704 - val_accuracy: 0.9032\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.9021\n",
      "Epoch 157: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3777 - accuracy: 0.9021 - val_loss: 0.3753 - val_accuracy: 0.9032\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.9029\n",
      "Epoch 158: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3757 - accuracy: 0.9029 - val_loss: 0.3652 - val_accuracy: 0.9074\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.9016\n",
      "Epoch 159: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3763 - accuracy: 0.9016 - val_loss: 0.3668 - val_accuracy: 0.9058\n",
      "Epoch 160/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.9030\n",
      "Epoch 160: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3746 - accuracy: 0.9030 - val_loss: 0.3646 - val_accuracy: 0.9068\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.9038\n",
      "Epoch 161: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3766 - accuracy: 0.9038 - val_loss: 0.3659 - val_accuracy: 0.9058\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.9024\n",
      "Epoch 162: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3757 - accuracy: 0.9024 - val_loss: 0.3696 - val_accuracy: 0.9055\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.9037\n",
      "Epoch 163: val_accuracy did not improve from 0.90740\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3722 - accuracy: 0.9037 - val_loss: 0.3709 - val_accuracy: 0.9022\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.9014\n",
      "Epoch 164: val_accuracy improved from 0.90740 to 0.90850, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3785 - accuracy: 0.9014 - val_loss: 0.3633 - val_accuracy: 0.9085\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.9048\n",
      "Epoch 165: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3717 - accuracy: 0.9048 - val_loss: 0.3657 - val_accuracy: 0.9056\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.9029\n",
      "Epoch 166: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3744 - accuracy: 0.9029 - val_loss: 0.3697 - val_accuracy: 0.9060\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3754 - accuracy: 0.9029\n",
      "Epoch 167: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3754 - accuracy: 0.9029 - val_loss: 0.3659 - val_accuracy: 0.9068\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.9037\n",
      "Epoch 168: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3728 - accuracy: 0.9037 - val_loss: 0.3666 - val_accuracy: 0.9059\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.9054\n",
      "Epoch 169: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3713 - accuracy: 0.9054 - val_loss: 0.3625 - val_accuracy: 0.9073\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.9046\n",
      "Epoch 170: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3706 - accuracy: 0.9046 - val_loss: 0.3729 - val_accuracy: 0.9010\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.9035\n",
      "Epoch 171: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3740 - accuracy: 0.9035 - val_loss: 0.3766 - val_accuracy: 0.9002\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.9034\n",
      "Epoch 172: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3731 - accuracy: 0.9034 - val_loss: 0.3625 - val_accuracy: 0.9066\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.9049\n",
      "Epoch 173: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3695 - accuracy: 0.9049 - val_loss: 0.3679 - val_accuracy: 0.9037\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.9042\n",
      "Epoch 174: val_accuracy did not improve from 0.90850\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3724 - accuracy: 0.9042 - val_loss: 0.3707 - val_accuracy: 0.9034\n",
      "Epoch 175/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3705 - accuracy: 0.9039\n",
      "Epoch 175: val_accuracy improved from 0.90850 to 0.90940, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3711 - accuracy: 0.9038 - val_loss: 0.3592 - val_accuracy: 0.9094\n",
      "Epoch 176/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.9040\n",
      "Epoch 176: val_accuracy did not improve from 0.90940\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3722 - accuracy: 0.9038 - val_loss: 0.3633 - val_accuracy: 0.9052\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.9039\n",
      "Epoch 177: val_accuracy did not improve from 0.90940\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3716 - accuracy: 0.9039 - val_loss: 0.3639 - val_accuracy: 0.9058\n",
      "Epoch 178/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3682 - accuracy: 0.9042\n",
      "Epoch 178: val_accuracy did not improve from 0.90940\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3676 - accuracy: 0.9044 - val_loss: 0.3608 - val_accuracy: 0.9088\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.9058\n",
      "Epoch 179: val_accuracy did not improve from 0.90940\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.3690 - accuracy: 0.9058 - val_loss: 0.3640 - val_accuracy: 0.9059\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.9059\n",
      "Epoch 180: val_accuracy did not improve from 0.90940\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3695 - accuracy: 0.9059 - val_loss: 0.3650 - val_accuracy: 0.9082\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.9043\n",
      "Epoch 181: val_accuracy did not improve from 0.90940\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3718 - accuracy: 0.9043 - val_loss: 0.3648 - val_accuracy: 0.9062\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.9058\n",
      "Epoch 182: val_accuracy did not improve from 0.90940\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.3670 - accuracy: 0.9058 - val_loss: 0.3642 - val_accuracy: 0.9069\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.9046\n",
      "Epoch 183: val_accuracy improved from 0.90940 to 0.91160, saving model to best_model.keras\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3682 - accuracy: 0.9046 - val_loss: 0.3576 - val_accuracy: 0.9116\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.9031\n",
      "Epoch 184: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3710 - accuracy: 0.9031 - val_loss: 0.3645 - val_accuracy: 0.9041\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.9052\n",
      "Epoch 185: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3676 - accuracy: 0.9052 - val_loss: 0.3566 - val_accuracy: 0.9097\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.9056\n",
      "Epoch 186: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3662 - accuracy: 0.9056 - val_loss: 0.3603 - val_accuracy: 0.9072\n",
      "Epoch 187/200\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.3672 - accuracy: 0.9039\n",
      "Epoch 187: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3669 - accuracy: 0.9042 - val_loss: 0.3594 - val_accuracy: 0.9089\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.9069\n",
      "Epoch 188: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3642 - accuracy: 0.9069 - val_loss: 0.3622 - val_accuracy: 0.9068\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.9059\n",
      "Epoch 189: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3670 - accuracy: 0.9059 - val_loss: 0.3624 - val_accuracy: 0.9064\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.9042\n",
      "Epoch 190: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3695 - accuracy: 0.9042 - val_loss: 0.3642 - val_accuracy: 0.9055\n",
      "Epoch 191/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.9080\n",
      "Epoch 191: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3637 - accuracy: 0.9080 - val_loss: 0.3592 - val_accuracy: 0.9079\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.9059\n",
      "Epoch 192: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3657 - accuracy: 0.9059 - val_loss: 0.3608 - val_accuracy: 0.9071\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.9052\n",
      "Epoch 193: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3685 - accuracy: 0.9052 - val_loss: 0.3619 - val_accuracy: 0.9070\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.9062\n",
      "Epoch 194: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3670 - accuracy: 0.9062 - val_loss: 0.3583 - val_accuracy: 0.9113\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.9058\n",
      "Epoch 195: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3653 - accuracy: 0.9058 - val_loss: 0.3564 - val_accuracy: 0.9084\n",
      "Epoch 196/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.9060\n",
      "Epoch 196: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3658 - accuracy: 0.9060 - val_loss: 0.3753 - val_accuracy: 0.9017\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.9069\n",
      "Epoch 197: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3659 - accuracy: 0.9069 - val_loss: 0.3549 - val_accuracy: 0.9111\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.9076\n",
      "Epoch 198: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3634 - accuracy: 0.9076 - val_loss: 0.3572 - val_accuracy: 0.9088\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.9061\n",
      "Epoch 199: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.3662 - accuracy: 0.9061 - val_loss: 0.3580 - val_accuracy: 0.9089\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.9048\n",
      "Epoch 200: val_accuracy did not improve from 0.91160\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3660 - accuracy: 0.9048 - val_loss: 0.3703 - val_accuracy: 0.9007\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                18464     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74538 (291.16 KB)\n",
      "Trainable params: 74538 (291.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.3757 - accuracy: 0.9048\n",
      "Test loss: 0.3757075071334839, test accuracy: 0.9047999978065491\n"
     ]
    }
   ],
   "source": [
    "activation = \"leaky_relu\"\n",
    "regularizer=0.002\n",
    "\n",
    "model = create_model(activation=activation, regularizer=regularizer)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# !rm -rf ./logs/fit/model_{activation}/reg_{regularizer}\n",
    "\n",
    "# log_folder = f\"./logs/fit/model_{activation}/reg_{regularizer}\"\n",
    "early_stopping = EarlyStopping(patience=20, monitor='val_accuracy')\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "# tensorboard = TensorBoard(log_dir=log_folder)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=200, \n",
    "    batch_size=1024,\n",
    "    validation_data=(x_validation, y_validation),\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    "\n",
    ")\n",
    "best_model = tf.keras.models.load_model('best_model.keras')\n",
    "best_model.summary()\n",
    "test_loss, test_accuracy = best_model.evaluate(test_images, test_labels)\n",
    "print(f\"Test loss: {test_loss}, test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "105dfcf5-c5f7-4837-9e51-43ed0213c234",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = history.history\n",
    "loss_values = history['loss']\n",
    "val_loss_values = history['val_loss']\n",
    "\n",
    "epochs = range(1, len(history['accuracy']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss'),\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "val_acc_values = history['val_accuracy']\n",
    "plt.plot(epochs, history['accuracy'], 'bo', label='Training acc')\n",
    "plt.plot(epochs, history['val_accuracy'], 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88b26a-916e-4270-8aec-fd24577f07a7",
   "metadata": {},
   "source": [
    "За допомогою згорткових мереж вдалось досягнути покращення з 0.8963 до 0.9047."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
